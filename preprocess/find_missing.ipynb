{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 videoID가 양쪽 파일에 존재합니다. 결과 파일은 비어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 (필요에 따라 경로 수정)\n",
    "file1 = 'C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/video_categories_with_top.csv'\n",
    "file2 = 'C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/pos_tagged_data_with_category.csv'\n",
    "\n",
    "# 두 CSV 파일 읽기\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "# 각 파일의 videoID 집합 생성\n",
    "videoIDs1 = set(df1['videoID'])\n",
    "videoIDs2 = set(df2['videoID'])\n",
    "\n",
    "# file1에는 있는데 file2에는 없는 videoID와 file2에는 있는데 file1에는 없는 videoID 계산\n",
    "only_in_file1 = videoIDs1 - videoIDs2\n",
    "only_in_file2 = videoIDs2 - videoIDs1\n",
    "\n",
    "# 결과 DataFrame 생성 (어느 파일에만 존재하는지 정보도 추가)\n",
    "df_missing_file1 = pd.DataFrame({'videoID': list(only_in_file1), 'source': 'file1'})\n",
    "df_missing_file2 = pd.DataFrame({'videoID': list(only_in_file2), 'source': 'file2'})\n",
    "\n",
    "# 두 DataFrame을 합침\n",
    "df_missing = pd.concat([df_missing_file1, df_missing_file2], ignore_index=True)\n",
    "\n",
    "# 결과 CSV 파일 경로 설정\n",
    "output_file = 'C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/missing_videoIDs.csv'\n",
    "\n",
    "# 결과 DataFrame이 비어 있는지 확인\n",
    "if df_missing.empty:\n",
    "    print(\"모든 videoID가 양쪽 파일에 존재합니다. 결과 파일은 비어 있습니다.\")\n",
    "else:\n",
    "    # 결과 CSV 파일로 저장\n",
    "    df_missing.to_csv(output_file, index=False)\n",
    "    print(\"비교 결과, 한쪽 파일에만 존재하는 videoID가 '{}' 파일에 저장되었습니다.\".format(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복된 videoID를 가진 총 202 행이 있습니다.\n",
      "중복된 행들이 'C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/duplicate_videoIDs.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_duplicate_videoid_rows(df, output_path, videoid_col='videoID'):\n",
    "    \"\"\"\n",
    "    주어진 DataFrame에서 videoID가 중복되어 나타나는 행들을 찾고,\n",
    "    중복된 행의 총 개수를 출력한 후, 결과를 CSV 파일로 저장하는 함수입니다.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): 분석할 DataFrame\n",
    "        output_path (str): 중복 행들을 저장할 CSV 파일 경로\n",
    "        videoid_col (str): videoID가 저장된 컬럼명 (기본값: 'videoID')\n",
    "    \"\"\"\n",
    "    # videoID 컬럼 기준으로 중복된 모든 행 찾기 (keep=False: 모든 중복 행 표시)\n",
    "    dup_rows = df[df.duplicated(subset=videoid_col, keep=False)]\n",
    "    \n",
    "    # 중복된 행의 총 개수\n",
    "    count_dup = dup_rows.shape[0]\n",
    "    \n",
    "    print(f\"중복된 videoID를 가진 총 {count_dup} 행이 있습니다.\")\n",
    "    \n",
    "    # 중복된 행들을 CSV 파일로 저장\n",
    "    dup_rows.to_csv(output_path, index=False)\n",
    "    print(f\"중복된 행들이 '{output_path}'에 저장되었습니다.\")\n",
    "\n",
    "# 예시 사용법: pos_tagged_data_with_category.csv 파일 읽고 함수 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 파일 경로에 맞게 CSV 파일 읽기\n",
    "    df_pos = pd.read_csv('C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/pos_tagged_data_with_category.csv')\n",
    "    \n",
    "    # 중복된 videoID 행을 저장할 파일 경로 설정\n",
    "    output_file = 'C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/duplicate_videoIDs.csv'\n",
    "    \n",
    "    # 함수 실행\n",
    "    save_duplicate_videoid_rows(df_pos, output_file, videoid_col='videoID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 행 개수: 101537, 중복 제거 후 행 개수: 101436\n",
      "중복된 videoID가 제거된 파일이 'C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/pos_tagged_data_with_category_unique.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로에 맞게 CSV 파일 읽기\n",
    "input_file = 'C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/pos_tagged_data_with_category.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# videoID 컬럼을 기준으로 중복 제거 (첫번째 행만 남김)\n",
    "df_unique = df.drop_duplicates(subset='videoID', keep='first')\n",
    "\n",
    "# 중복 제거된 데이터프레임의 행 개수 출력\n",
    "print(f\"원본 행 개수: {df.shape[0]}, 중복 제거 후 행 개수: {df_unique.shape[0]}\")\n",
    "\n",
    "# 결과 CSV 파일로 저장\n",
    "output_file = 'C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/pos_tagged_data_with_category_unique.csv'\n",
    "df_unique.to_csv(output_file, index=False)\n",
    "print(f\"중복된 videoID가 제거된 파일이 '{output_file}'에 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YT_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
