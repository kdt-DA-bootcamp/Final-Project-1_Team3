import os
import csv
import time
import requests
from dotenv import load_dotenv
from more_itertools import chunked  # pip install more-itertools
import pandas as pd

# ğŸ“Œ 1. .envì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
api_keys = [
    os.environ[key]
    for key in sorted(
        [k for k in os.environ if k.startswith("API_KEY_")],
        key=lambda x: int(x.split("_")[2]) if x.split("_")[2].isdigit() else 0
    )
]
api_index = 0

def get_api_key():
    global api_index
    if api_index >= len(api_keys):
        raise RuntimeError("âŒ ëª¨ë“  API í‚¤ì˜ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return api_keys[api_index]

def switch_api_key():
    global api_index
    api_index += 1
    if api_index < len(api_keys):
        print(f"ğŸ” API í‚¤ ì „í™˜ â†’ {api_index + 1}ë²ˆì§¸ í‚¤ ì‚¬ìš©")
    else:
        raise RuntimeError("âŒ ë” ì´ìƒ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

def get_channel_infos_batch(channel_ids):
    while True:
        api_key = get_api_key()
        ids = ",".join(channel_ids)
        url = f"https://www.googleapis.com/youtube/v3/channels?part=snippet,statistics&id={ids}&key={api_key}"
        response = requests.get(url)

        if response.status_code == 403:
            error_reason = response.json().get("error", {}).get("errors", [{}])[0].get("reason", "")
            if error_reason in ["quotaExceeded", "userRateLimitExceeded"]:
                print(f"âš ï¸ API í‚¤ {api_index + 1} í• ë‹¹ëŸ‰ ì´ˆê³¼")
                switch_api_key()
                continue
            else:
                print(f"âŒ ì ‘ê·¼ ì˜¤ë¥˜: {response.text}")
                return []
        elif response.status_code != 200:
            print(f"âŒ ê¸°íƒ€ ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return []

        results = []
        for item in response.json().get("items", []):
            snippet = item['snippet']
            stats = item['statistics']
            results.append({
                "channelID": item['id'],
                "channelTitle": snippet.get('title', ''),
                "subscriberCount": stats.get('subscriberCount', '0'),
                "totalViews": stats.get('viewCount', '0'),
                "videosCount": stats.get('videoCount', '0')
            })
        return results

# ğŸ“Œ 2. ìˆ˜ì§‘í•  ì±„ë„ ID ë¦¬ìŠ¤íŠ¸ ì •ì˜
channel_ids = [
    "UCOWK2xUc1c6fdytaJnETnLg"
]

# ğŸ“Œ 3. ì €ì¥ ê²½ë¡œ ì§€ì •
output_path = "channel_info_result.csv"

# ğŸ“Œ 4. ê²°ê³¼ ì €ì¥
with open(output_path, mode='w', newline='', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=["channelID", "channelTitle", "subscriberCount", "totalViews", "videosCount"])
    writer.writeheader()

    for i, batch in enumerate(chunked(channel_ids, 50)):
        print(f"ğŸ” Batch {i+1}: {len(batch)}ê°œ ì±„ë„ ìš”ì²­ ì¤‘...")
        try:
            results = get_channel_infos_batch(batch)
            for info in results:
                writer.writerow(info)
            f.flush()
        except RuntimeError as e:
            print(str(e))
            break
        time.sleep(1.1)  # Rate limit ë°©ì§€

print(f"\nâœ… ì™„ë£Œ! ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_path}")
