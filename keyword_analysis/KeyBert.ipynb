{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\.conda\\envs\\YT_project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\hp\\.conda\\envs\\YT_project\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "import ast\n",
    "\n",
    "# âœ… 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/video_data_db_with_img.csv\").head(100)\n",
    "\n",
    "# âœ… 2. tags ì»¬ëŸ¼: ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "df[\"tags\"] = df[\"tags\"].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) and x.startswith(\"[\") else [])\n",
    "\n",
    "# âœ… 3. title + tags + img_text â†’ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ê²°í•©\n",
    "df[\"combined_text\"] = (\n",
    "    df[\"title\"].fillna(\"\") + \" \" +\n",
    "    df[\"tags\"].apply(lambda tags: \" \".join(tags)) + \" \" +\n",
    "    df[\"img_text\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "# âœ… 4. categoryID â†’ ì¹´í…Œê³ ë¦¬ëª… ë§¤í•‘\n",
    "category_map = {\n",
    "    1: \"ì—”í„°í…Œì¸ë¨¼íŠ¸\", 2: \"ì°¨ëŸ‰\", 3: \"ì—¬í–‰/ìŒì‹\", 4: \"ê²Œì„\",\n",
    "    5: \"ìŠ¤í¬ì¸ \", 6: \"ë¼ì´í”„\", 7: \"ì •ì¹˜\", 8: \"ë°˜ë ¤ë™ë¬¼\",\n",
    "    9: \"êµìœ¡\", 10: \"ê³¼í•™/ê¸°ìˆ \"\n",
    "}\n",
    "df[\"category_name\"] = df[\"categoryID\"].map(category_map)\n",
    "\n",
    "# âœ… 5. KeyBERT ëª¨ë¸ ë¡œë”©\n",
    "kw_model = KeyBERT(model='paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# âœ… 6. í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜\n",
    "def extract_keywords(text):\n",
    "    keywords = kw_model.extract_keywords(text, top_n=5)\n",
    "    return [kw[0] for kw in keywords]\n",
    "\n",
    "# âœ… 7. ì „ì²´ ë¬¸ì¥ì— ëŒ€í•´ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹œê°„ ì†Œìš”ë  ìˆ˜ ìˆìŒ)\n",
    "df[\"keywords\"] = df[\"combined_text\"].apply(extract_keywords)\n",
    "\n",
    "# âœ… 8. ê²°ê³¼ ì €ì¥ (ì„ íƒ)\n",
    "df.to_csv(\"video_data_with_keywords.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# âœ… íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "INPUT_PATH = \"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/video_data_db_with_img.csv\"\n",
    "OUTPUT_PATH = \"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/video_data_with_keywords.csv\"\n",
    "SAVE_EVERY = 500  # ëª‡ ê°œë§ˆë‹¤ ì €ì¥í• ì§€ ì„¤ì •\n",
    "\n",
    "# âœ… KeyBERT ëª¨ë¸ ë¡œë”©\n",
    "kw_model = KeyBERT(model='paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# âœ… ê¸°ì¡´ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸° (ìˆìœ¼ë©´ ì´ì–´ì„œ)\n",
    "if os.path.exists(OUTPUT_PATH):\n",
    "    print(\"ğŸ” ê¸°ì¡´ ê²°ê³¼ ì´ì–´ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...\")\n",
    "    df = pd.read_csv(OUTPUT_PATH)\n",
    "    df[\"keywords\"] = df[\"keywords\"].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) and isinstance(x, str) and x.startswith(\"[\") else [])\n",
    "else:\n",
    "    df = pd.read_csv(INPUT_PATH)\n",
    "    df[\"tags\"] = df[\"tags\"].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) and x.startswith(\"[\") else [])\n",
    "    df[\"combined_text\"] = (\n",
    "        df[\"title\"].fillna(\"\") + \" \" +\n",
    "        df[\"tags\"].apply(lambda tags: \" \".join(tags)) + \" \" +\n",
    "        df[\"img_text\"].fillna(\"\")\n",
    "    )\n",
    "    category_map = {\n",
    "        1: \"ì—”í„°í…Œì¸ë¨¼íŠ¸\", 2: \"ì°¨ëŸ‰\", 3: \"ì—¬í–‰/ìŒì‹\", 4: \"ê²Œì„\",\n",
    "        5: \"ìŠ¤í¬ì¸ \", 6: \"ë¼ì´í”„\", 7: \"ì •ì¹˜\", 8: \"ë°˜ë ¤ë™ë¬¼\",\n",
    "        9: \"êµìœ¡\", 10: \"ê³¼í•™/ê¸°ìˆ \"\n",
    "    }\n",
    "    df[\"category_name\"] = df[\"categoryID\"].map(category_map)\n",
    "    df[\"keywords\"] = None  # ì´ˆê¸°í™”\n",
    "\n",
    "# âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘\n",
    "start_time = time.time()\n",
    "total = len(df)\n",
    "\n",
    "print(f\"ğŸ“¦ ì´ {total}ê°œ ì¤‘, í‚¤ì›Œë“œ ë¯¸ì¶”ì¶œ í•­ëª©ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "for i in tqdm(range(total), desc=\"ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘\"):\n",
    "    # ì´ë¯¸ ì²˜ë¦¬ëœ ê²½ìš° ê±´ë„ˆëœ€\n",
    "    if pd.notnull(df.at[i, \"keywords\"]) and df.at[i, \"keywords\"] not in [[], \"[]\", \"None\", None]:\n",
    "        continue\n",
    "\n",
    "    text = df.at[i, \"combined_text\"]\n",
    "    keywords = kw_model.extract_keywords(text, top_n=5)\n",
    "    df.at[i, \"keywords\"] = [kw[0] for kw in keywords]\n",
    "\n",
    "    # ì¤‘ê°„ ì €ì¥\n",
    "    if i % SAVE_EVERY == 0 and i > 0:\n",
    "        df.to_csv(OUTPUT_PATH, index=False)\n",
    "        elapsed = time.time() - start_time\n",
    "        avg = elapsed / (i+1)\n",
    "        remaining = (total - i - 1) * avg\n",
    "        print(f\"\\nğŸ’¾ ì¤‘ê°„ ì €ì¥: {i}/{total} â–¶ ê²½ê³¼: {elapsed:.1f}s | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining/60:.1f}ë¶„\")\n",
    "\n",
    "# âœ… ìµœì¢… ì €ì¥\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nâœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {elapsed/60:.2f}ë¶„\")\n",
    "print(f\"ğŸ“ ì €ì¥ ìœ„ì¹˜: {OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YT_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
