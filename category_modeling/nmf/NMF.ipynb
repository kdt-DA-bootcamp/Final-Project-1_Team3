{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data Shape: (57039, 8)\n",
      "Topic #0: 챌린지 dance 춤추는곰돌 afstarz music kpop cola 춤추는나율 어깨댄스챌린지 쇼츠\n",
      "Topic #1: 코디 데일리룩 패션 룩북 ootd fashion 봄코디 스타일링 데일리룩코디 중년패션코디\n",
      "Topic #2: 먹방 mukbang asmr eating food korean 요리 맛집 sound 레시피\n",
      "Topic #3: 추천 top10 후기 판매순위 비교 가격 평점 가장 리뷰 요즘\n",
      "Topic #4: 메이크업 makeup makeuptutorial 메이크업튜토리얼 beauty tutorial grwm 데일리 모카무스 뷰티\n",
      "Topic #5: 브이로그 vlog 일상 아기 직장인 언박싱 여행 육아 일상브이로그 baby\n",
      "Topic #6: 콘서트 shorts 0100 6404 02 행사섭외문의 공연행사섭외문의 서산 윤형주 2025\n",
      "Topic #7: 아이브 포카포장 챌린지 언박싱 ive 포장계 다이브 추천 아이돌 알고리즘\n",
      "Topic #8: 룩북 lookbook ai 4k 직캠 란제리 모델 underwear 비키니 bikini\n",
      "Topic #9: 만들기 인형계 레시피 인형 비즈키링 diy 요리 관리자님추천뜨게해주세요 키링 인형계브이로그\n",
      "NMF 토픽 모델링 결과가 'nmf_topics_new.txt' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# 1. CSV 파일 로드\n",
    "input_file = \"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/preprocessed_data_unique.csv\"  # 전처리된 CSV 파일 경로\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 1-1. categoryID가 6인 데이터만 필터링\n",
    "df = df[df['categoryID'] == 6].reset_index(drop=True)\n",
    "print(\"Filtered Data Shape:\", df.shape)\n",
    "\n",
    "# 2. combined_text 열 생성: 만약 combined_text가 없으면, title, tags, img_text를 결합\n",
    "if \"combined_text\" not in df.columns:\n",
    "    # 각 열의 결측치는 빈 문자열로 처리하여 결합\n",
    "    df[\"combined_text\"] = (\n",
    "        df[\"title\"].fillna(\"\") + \" \" +\n",
    "        df[\"tags\"].fillna(\"\") + \" \" +\n",
    "        df[\"img_text\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "# 3. 결합된 텍스트를 문서 리스트로 생성\n",
    "docs = df[\"combined_text\"].fillna(\"\").tolist()\n",
    "\n",
    "# 4. TF-IDF 행렬 생성\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "# 5. NMF 모델 학습\n",
    "n_topics = 10  # 원하는 토픽 수\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf_model.fit_transform(tfidf)  # 문서-토픽 행렬\n",
    "H = nmf_model.components_           # 토픽-단어 행렬\n",
    "\n",
    "# 6. 각 토픽별 상위 단어 추출 함수\n",
    "def get_top_words(model, feature_names, n_top_words=10):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topics.append(\" \".join(top_words))\n",
    "    return topics\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "topics = get_top_words(nmf_model, feature_names, n_top_words=10)\n",
    "\n",
    "# 7. 토픽 결과 출력 및 파일로 저장\n",
    "for i, topic in enumerate(topics):\n",
    "    print(\"Topic #{}: {}\".format(i, topic))\n",
    "\n",
    "with open(\"nmf_topics_new.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, topic in enumerate(topics):\n",
    "        f.write(\"Topic #{}: {}\\n\".format(i, topic))\n",
    "\n",
    "print(\"NMF 토픽 모델링 결과가 'nmf_topics_new.txt' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: 챌린지 dance 춤추는곰돌 afstarz kpop music cola 춤추는나율 쇼츠 어깨댄스챌린지\n",
      "Topic #1: 먹방 mukbang asmr eating food korean 맛집 요리 sound 레시피\n",
      "Topic #2: 플레이리스트 playlist 노래 음악 팝송 플리 music 감성 𝐏𝐥𝐚𝐲𝐥𝐢𝐬𝐭 좋은\n",
      "Topic #3: 룩북 코디 lookbook 데일리룩 ai 패션 ootd fashion 중년패션코디 데일리룩코디\n",
      "Topic #4: 동요 어린이 kids 노래 애니메이션 교육 아기 유아 유치원 songs\n",
      "Topic #5: 추천 영화 리뷰 비교 후기 top10 가격 판매순위 스마트폰 가장\n",
      "Topic #6: 메이크업 makeup makeuptutorial 메이크업튜토리얼 모카무스 tutorial 뷰티 beauty shorts grwm\n",
      "Topic #7: 직캠 아이돌 shorts 치어리더 fancam 콘서트 4k kpop 하이라이트 라이브\n",
      "Topic #8: 브이로그 vlog 일상 여행 언박싱 직장인 아기 맛집 일본 일상브이로그\n",
      "Topic #9: 영어단어공부법 영어단어외우기 영어단어공부 5초안에 대답 5초 몰라 영어로 이거 공부\n",
      "Topic #10: 만들기 diy squishy nano tape 실리콘테이프 인형계 말랑이 orbeez 레시피\n",
      "NMF 토픽 모델링 결과가 'nmf_topics_11.txt' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# 1. CSV 파일 로드\n",
    "input_file = \"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/preprocessed_data_comp.csv\"  # 전처리된 CSV 파일 경로\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 2. combined_text 열 생성: 만약 combined_text가 없으면, title, tags, img_text를 결합\n",
    "if \"combined_text\" not in df.columns:\n",
    "    # 각 열의 결측치는 빈 문자열로 처리하여 결합\n",
    "    df[\"combined_text\"] = (\n",
    "        df[\"title\"].fillna(\"\") + \" \" +\n",
    "        df[\"tags\"].fillna(\"\") + \" \" +\n",
    "        df[\"img_text\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "# 3. 결합된 텍스트를 문서 리스트로 생성\n",
    "docs = df[\"combined_text\"].fillna(\"\").tolist()\n",
    "\n",
    "# 4. TF-IDF 행렬 생성\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "# 5. NMF 모델 학습\n",
    "n_topics = 11  # 원하는 토픽 수\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf_model.fit_transform(tfidf)  # 문서-토픽 행렬\n",
    "H = nmf_model.components_           # 토픽-단어 행렬\n",
    "\n",
    "# 6. 각 토픽별 상위 단어 추출 함수\n",
    "def get_top_words(model, feature_names, n_top_words=10):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topics.append(\" \".join(top_words))\n",
    "    return topics\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "topics = get_top_words(nmf_model, feature_names, n_top_words=10)\n",
    "\n",
    "# 7. 토픽 결과 출력 및 파일로 저장\n",
    "for i, topic in enumerate(topics):\n",
    "    print(\"Topic #{}: {}\".format(i, topic))\n",
    "\n",
    "    with open(\"nmf_topics_11.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, topic in enumerate(topics):\n",
    "            f.write(\"Topic #{}: {}\\n\".format(i, topic))\n",
    "\n",
    "print(\"NMF 토픽 모델링 결과가 'nmf_topics_11.txt' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: 챌린지 dance 춤추는곰돌 afstarz kpop music cola 쇼츠 춤추는나율 어깨댄스챌린지\n",
      "Topic #1: 먹방 mukbang asmr eating food korean 맛집 show 요리 sound\n",
      "Topic #2: 플레이리스트 playlist 노래 음악 팝송 플리 music 감성 𝐏𝐥𝐚𝐲𝐥𝐢𝐬𝐭 좋은\n",
      "Topic #3: 룩북 코디 lookbook 데일리룩 ai 패션 fashion ootd 중년패션코디 데일리룩코디\n",
      "Topic #4: 동요 어린이 kids 노래 애니메이션 교육 아기 유아 유치원 songs\n",
      "Topic #5: 추천 비교 top10 후기 리뷰 가격 판매순위 스마트폰 가장 top\n",
      "Topic #6: 메이크업 makeup makeuptutorial 메이크업튜토리얼 모카무스 tutorial shorts 뷰티 beauty grwm\n",
      "Topic #7: 직캠 아이돌 shorts 치어리더 콘서트 fancam 4k kpop 2025 라이브\n",
      "Topic #8: 브이로그 vlog 일상 여행 언박싱 직장인 아기 맛집 일본 일상브이로그\n",
      "Topic #9: 영어단어공부법 영어단어외우기 영어단어공부 5초안에 대답 5초 몰라 영어로 이거 공부\n",
      "Topic #10: 만들기 diy squishy nano tape with 실리콘테이프 말랑이 인형계 orbeez\n",
      "Topic #11: 영화 드라마 명장면 배우 넷플릭스 결말포함 리뷰 영화리뷰 shorts 영화추천\n",
      "NMF 토픽 모델링 결과가 'nmf_topics_12.txt' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# 1. CSV 파일 로드\n",
    "input_file = \"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/preprocessed_data_comp.csv\"  # 전처리된 CSV 파일 경로\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 2. combined_text 열 생성: 만약 combined_text가 없으면, title, tags, img_text를 결합\n",
    "if \"combined_text\" not in df.columns:\n",
    "    # 각 열의 결측치는 빈 문자열로 처리하여 결합\n",
    "    df[\"combined_text\"] = (\n",
    "        df[\"title\"].fillna(\"\") + \" \" +\n",
    "        df[\"tags\"].fillna(\"\") + \" \" +\n",
    "        df[\"img_text\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "# 3. 결합된 텍스트를 문서 리스트로 생성\n",
    "docs = df[\"combined_text\"].fillna(\"\").tolist()\n",
    "\n",
    "# 4. TF-IDF 행렬 생성\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "# 5. NMF 모델 학습\n",
    "n_topics = 12  # 원하는 토픽 수\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf_model.fit_transform(tfidf)  # 문서-토픽 행렬\n",
    "H = nmf_model.components_           # 토픽-단어 행렬\n",
    "\n",
    "# 6. 각 토픽별 상위 단어 추출 함수\n",
    "def get_top_words(model, feature_names, n_top_words=10):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topics.append(\" \".join(top_words))\n",
    "    return topics\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "topics = get_top_words(nmf_model, feature_names, n_top_words=10)\n",
    "\n",
    "# 7. 토픽 결과 출력 및 파일로 저장\n",
    "for i, topic in enumerate(topics):\n",
    "    print(\"Topic #{}: {}\".format(i, topic))\n",
    "\n",
    "    with open(\"nmf_topics_12.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, topic in enumerate(topics):\n",
    "            f.write(\"Topic #{}: {}\\n\".format(i, topic))\n",
    "\n",
    "print(\"NMF 토픽 모델링 결과가 'nmf_topics_12.txt' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: 챌린지 dance 춤추는곰돌 afstarz kpop music cola 쇼츠 춤추는나율 어깨댄스챌린지\n",
      "Topic #1: 먹방 mukbang asmr eating food korean 맛집 요리 sound 레시피\n",
      "Topic #2: 플레이리스트 playlist 노래 음악 팝송 플리 music 감성 𝐏𝐥𝐚𝐲𝐥𝐢𝐬𝐭 좋은\n",
      "Topic #3: 룩북 코디 lookbook 데일리룩 ai 패션 ootd fashion 중년패션코디 데일리룩코디\n",
      "Topic #4: 동요 어린이 kids 노래 애니메이션 교육 아기 유아 유치원 songs\n",
      "Topic #5: 추천 비교 top10 후기 리뷰 판매순위 가격 스마트폰 가장 평점\n",
      "Topic #6: 메이크업 makeup makeuptutorial 메이크업튜토리얼 모카무스 shorts tutorial beauty 뷰티 grwm\n",
      "Topic #7: 직캠 아이돌 치어리더 fancam 4k kpop 아이브 shorts 공연 하츠투하츠\n",
      "Topic #8: 브이로그 vlog 일상 여행 언박싱 직장인 아기 맛집 일본 일상브이로그\n",
      "Topic #9: 영어단어공부법 영어단어외우기 영어단어공부 5초안에 대답 5초 몰라 영어로 이거 공부\n",
      "Topic #10: 만들기 diy squishy nano tape 실리콘테이프 인형계 말랑이 orbeez 레시피\n",
      "Topic #11: 콘서트 2025 하이라이트 02 0100 6404 shorts 행사섭외문의 vs 플레이브\n",
      "Topic #12: 영화 드라마 명장면 배우 넷플릭스 결말포함 리뷰 영화리뷰 shorts 영화추천\n",
      "NMF 토픽 모델링 결과가 'nmf_topics_13.txt' 파일에 저장되었습니다.\n",
      "NMF 모델과 TF-IDF 벡터라이저가 각각 'nmf_model_13.pkl'과 'tfidf_vectorizer_13.pkl' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# 1. CSV 파일 로드\n",
    "input_file = \"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/preprocessed_data_comp.csv\"  # 전처리된 CSV 파일 경로\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 2. combined_text 열 생성: 만약 combined_text가 없으면, title, tags, img_text를 결합\n",
    "if \"combined_text\" not in df.columns:\n",
    "    # 각 열의 결측치는 빈 문자열로 처리하여 결합\n",
    "    df[\"combined_text\"] = (\n",
    "        df[\"title\"].fillna(\"\") + \" \" +\n",
    "        df[\"tags\"].fillna(\"\") + \" \" +\n",
    "        df[\"img_text\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "# 3. 결합된 텍스트를 문서 리스트로 생성\n",
    "docs = df[\"combined_text\"].fillna(\"\").tolist()\n",
    "\n",
    "# 4. TF-IDF 행렬 생성\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "# 5. NMF 모델 학습\n",
    "n_topics = 13  # 원하는 토픽 수\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf_model.fit_transform(tfidf)  # 문서-토픽 행렬\n",
    "H = nmf_model.components_           # 토픽-단어 행렬\n",
    "\n",
    "# 6. 각 토픽별 상위 단어 추출 함수\n",
    "def get_top_words(model, feature_names, n_top_words=10):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topics.append(\" \".join(top_words))\n",
    "    return topics\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "topics = get_top_words(nmf_model, feature_names, n_top_words=10)\n",
    "\n",
    "# 7. 토픽 결과 출력 및 파일로 저장\n",
    "for i, topic in enumerate(topics):\n",
    "    print(\"Topic #{}: {}\".format(i, topic))\n",
    "\n",
    "    with open(\"nmf_topics_13.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, topic in enumerate(topics):\n",
    "            f.write(\"Topic #{}: {}\\n\".format(i, topic))\n",
    "\n",
    "print(\"NMF 토픽 모델링 결과가 'nmf_topics_13.txt' 파일에 저장되었습니다.\")\n",
    "\n",
    "# 8. 모델과 벡터라이저 저장\n",
    "with open(\"nmf_model_13.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(nmf_model, model_file)\n",
    "with open(\"tfidf_vectorizer_13.pkl\", \"wb\") as vec_file:\n",
    "    pickle.dump(tfidf_vectorizer, vec_file)\n",
    "\n",
    "print(\"NMF 모델과 TF-IDF 벡터라이저가 각각 'nmf_model_13.pkl'과 'tfidf_vectorizer_13.pkl' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: 챌린지 dance 춤추는곰돌 afstarz kpop music cola 쇼츠 춤추는나율 어깨댄스챌린지\n",
      "Topic #1: 먹방 mukbang asmr eating food korean 맛집 요리 sound 레시피\n",
      "Topic #2: 플레이리스트 playlist 노래 음악 팝송 플리 music 감성 𝐏𝐥𝐚𝐲𝐥𝐢𝐬𝐭 좋은\n",
      "Topic #3: 코디 데일리룩 패션 ootd 중년패션코디 fashion 룩북 스타일링 데일리룩코디 봄코디\n",
      "Topic #4: 동요 어린이 kids 노래 애니메이션 교육 아기 유아 유치원 songs\n",
      "Topic #5: 추천 비교 top10 후기 리뷰 판매순위 가격 스마트폰 가장 평점\n",
      "Topic #6: 메이크업 makeup makeuptutorial 메이크업튜토리얼 모카무스 shorts tutorial beauty 뷰티 grwm\n",
      "Topic #7: 직캠 치어리더 콘서트 fancam shorts 2025 하이라이트 4k 02 라이브\n",
      "Topic #8: 브이로그 vlog 일상 여행 직장인 아기 맛집 일본 일상브이로그 육아\n",
      "Topic #9: 영어단어공부법 영어단어외우기 영어단어공부 5초안에 대답 5초 몰라 영어로 이거 공부\n",
      "Topic #10: 만들기 diy squishy nano tape 실리콘테이프 인형계 말랑이 orbeez 레시피\n",
      "Topic #11: 영화 드라마 명장면 배우 넷플릭스 결말포함 리뷰 영화리뷰 shorts 영화추천\n",
      "Topic #12: 룩북 lookbook ai 란제리 4k 모델 bikini 비키니 underwear 세로룩북\n",
      "Topic #13: 언박싱 unboxing asmr 피규어 아이브 선물 아이폰 하울 shorts 앨범\n",
      "Topic #14: 아이돌 플레이브 아이브 plave kpop 케이팝 ive 밤비 하민 포카포장\n",
      "NMF 토픽 모델링 결과가 'nmf_topics_14.txt' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# 1. CSV 파일 로드\n",
    "input_file = \"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/preprocessed_data_comp.csv\"  # 전처리된 CSV 파일 경로\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 2. combined_text 열 생성: 만약 combined_text가 없으면, title, tags, img_text를 결합\n",
    "if \"combined_text\" not in df.columns:\n",
    "    # 각 열의 결측치는 빈 문자열로 처리하여 결합\n",
    "    df[\"combined_text\"] = (\n",
    "        df[\"title\"].fillna(\"\") + \" \" +\n",
    "        df[\"tags\"].fillna(\"\") + \" \" +\n",
    "        df[\"img_text\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "# 3. 결합된 텍스트를 문서 리스트로 생성\n",
    "docs = df[\"combined_text\"].fillna(\"\").tolist()\n",
    "\n",
    "# 4. TF-IDF 행렬 생성\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "# 5. NMF 모델 학습\n",
    "n_topics = 15  # 원하는 토픽 수\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf_model.fit_transform(tfidf)  # 문서-토픽 행렬\n",
    "H = nmf_model.components_           # 토픽-단어 행렬\n",
    "\n",
    "# 6. 각 토픽별 상위 단어 추출 함수\n",
    "def get_top_words(model, feature_names, n_top_words=10):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topics.append(\" \".join(top_words))\n",
    "    return topics\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "topics = get_top_words(nmf_model, feature_names, n_top_words=10)\n",
    "\n",
    "# 7. 토픽 결과 출력 및 파일로 저장\n",
    "for i, topic in enumerate(topics):\n",
    "    print(\"Topic #{}: {}\".format(i, topic))\n",
    "\n",
    "    with open(\"nmf_topics_14.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, topic in enumerate(topics):\n",
    "            f.write(\"Topic #{}: {}\\n\".format(i, topic))\n",
    "\n",
    "print(\"NMF 토픽 모델링 결과가 'nmf_topics_14.txt' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: 챌린지 dance 춤추는곰돌 afstarz kpop music cola 쇼츠 춤추는나율 어깨댄스챌린지\n",
      "Topic #1: 먹방 mukbang asmr eating food korean 맛집 요리 sound 레시피\n",
      "Topic #2: 플레이리스트 playlist 노래 음악 팝송 플리 music 감성 𝐏𝐥𝐚𝐲𝐥𝐢𝐬𝐭 좋은\n",
      "Topic #3: 코디 데일리룩 패션 ootd 중년패션코디 fashion 룩북 스타일링 데일리룩코디 봄코디\n",
      "Topic #4: 동요 어린이 kids 노래 애니메이션 교육 아기 유아 유치원 songs\n",
      "Topic #5: 추천 비교 top10 후기 리뷰 판매순위 가격 스마트폰 가장 평점\n",
      "Topic #6: 메이크업 makeup makeuptutorial 메이크업튜토리얼 모카무스 shorts tutorial beauty 뷰티 grwm\n",
      "Topic #7: 직캠 치어리더 콘서트 fancam shorts 2025 하이라이트 4k 02 라이브\n",
      "Topic #8: 브이로그 vlog 일상 여행 직장인 아기 맛집 일본 일상브이로그 육아\n",
      "Topic #9: 영어단어공부법 영어단어외우기 영어단어공부 5초안에 대답 5초 몰라 영어로 이거 공부\n",
      "Topic #10: 만들기 diy squishy nano tape 실리콘테이프 인형계 말랑이 orbeez 레시피\n",
      "Topic #11: 영화 드라마 명장면 배우 넷플릭스 결말포함 리뷰 영화리뷰 shorts 영화추천\n",
      "Topic #12: 룩북 lookbook ai 란제리 4k 모델 bikini 비키니 underwear 세로룩북\n",
      "Topic #13: 언박싱 unboxing asmr 피규어 아이브 선물 아이폰 하울 shorts 앨범\n",
      "Topic #14: 아이돌 플레이브 아이브 plave kpop 케이팝 ive 밤비 하민 포카포장\n",
      "NMF 토픽 모델링 결과가 'nmf_topics_15.txt' 파일에 저장되었습니다.\n",
      "NMF 모델과 TF-IDF 벡터라이저가 각각 'nmf_model_15.pkl'과 'tfidf_vectorizer_15.pkl' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# 1. CSV 파일 로드\n",
    "input_file = \"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/preprocessed_data_comp.csv\"  # 전처리된 CSV 파일 경로\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 2. combined_text 열 생성: 만약 combined_text가 없으면, title, tags, img_text를 결합\n",
    "if \"combined_text\" not in df.columns:\n",
    "    # 각 열의 결측치는 빈 문자열로 처리하여 결합\n",
    "    df[\"combined_text\"] = (\n",
    "        df[\"title\"].fillna(\"\") + \" \" +\n",
    "        df[\"tags\"].fillna(\"\") + \" \" +\n",
    "        df[\"img_text\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "# 3. 결합된 텍스트를 문서 리스트로 생성\n",
    "docs = df[\"combined_text\"].fillna(\"\").tolist()\n",
    "\n",
    "# 4. TF-IDF 행렬 생성\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "# 5. NMF 모델 학습\n",
    "n_topics = 15  # 원하는 토픽 수\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf_model.fit_transform(tfidf)  # 문서-토픽 행렬\n",
    "H = nmf_model.components_           # 토픽-단어 행렬\n",
    "\n",
    "# 6. 각 토픽별 상위 단어 추출 함수\n",
    "def get_top_words(model, feature_names, n_top_words=10):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topics.append(\" \".join(top_words))\n",
    "    return topics\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "topics = get_top_words(nmf_model, feature_names, n_top_words=10)\n",
    "\n",
    "# 7. 토픽 결과 출력 및 파일로 저장\n",
    "for i, topic in enumerate(topics):\n",
    "    print(\"Topic #{}: {}\".format(i, topic))\n",
    "\n",
    "    with open(\"nmf_topics_15.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, topic in enumerate(topics):\n",
    "            f.write(\"Topic #{}: {}\\n\".format(i, topic))\n",
    "\n",
    "print(\"NMF 토픽 모델링 결과가 'nmf_topics_15.txt' 파일에 저장되었습니다.\")\n",
    "\n",
    "# 8. 모델과 벡터라이저 저장\n",
    "with open(\"nmf_model_15.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(nmf_model, model_file)\n",
    "with open(\"tfidf_vectorizer_15.pkl\", \"wb\") as vec_file:\n",
    "    pickle.dump(tfidf_vectorizer, vec_file)\n",
    "\n",
    "print(\"NMF 모델과 TF-IDF 벡터라이저가 각각 'nmf_model_15.pkl'과 'tfidf_vectorizer_15.pkl' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: 춤추는곰돌 afstarz dance cola music 춤추는나율 kpop 어깨댄스챌린지 춤추는나율cola 쇼츠\n",
      "Topic #1: 먹방 mukbang asmr eating food korean sound spicy 리얼사운드 real\n",
      "Topic #2: 플레이리스트 playlist 노래 음악 팝송 플리 music 감성 𝐏𝐥𝐚𝐲𝐥𝐢𝐬𝐭 좋은\n",
      "Topic #3: 코디 데일리룩 패션 ootd 중년패션코디 fashion 룩북 스타일링 데일리룩코디 봄코디\n",
      "Topic #4: 동요 어린이 kids 노래 애니메이션 교육 유아 유치원 아기 songs\n",
      "Topic #5: 추천 비교 top10 후기 판매순위 가격 리뷰 스마트폰 가장 평점\n",
      "Topic #6: 메이크업 makeup makeuptutorial 메이크업튜토리얼 모카무스 tutorial 뷰티 beauty 데일리 grwm\n",
      "Topic #7: 룩북 lookbook ai 란제리 4k 모델 bikini 비키니 underwear 세로룩북\n",
      "Topic #8: 브이로그 vlog 일상 직장인 여행 아기 일상브이로그 육아 커플 일본\n",
      "Topic #9: 영어단어공부법 영어단어외우기 영어단어공부 5초안에 대답 5초 몰라 영어로 이거 공부\n",
      "Topic #10: 만들기 diy squishy nano tape 실리콘테이프 말랑이 인형계 orbeez 볼펜\n",
      "Topic #11: shorts 아기 쇼츠 놀이 baby 커버 cute cover 육아 드라마\n",
      "Topic #12: 영화 드라마 명장면 넷플릭스 결말포함 배우 리뷰 영화리뷰 영화추천 결말\n",
      "Topic #13: 콘서트 0100 6404 02 행사섭외문의 공연행사섭외문의 박지현 윤형주 트로트 제니\n",
      "Topic #14: 언박싱 unboxing asmr 피규어 아이브 선물 아이폰 하울 리뷰 앨범\n",
      "Topic #15: 챌린지 아이브 challenge 포카포장 댄스 ive 포장계 dance 포카챌린지 틱톡\n",
      "Topic #16: 하이라이트 2025 vs 03 일정 25 live 라이브 계획 10\n",
      "Topic #17: 직캠 아이돌 fancam 치어리더 4k kpop 하츠투하츠 공연 pop mpd직캠\n",
      "Topic #18: 맛집 레시피 여행 요리 food 집밥 cooking 일본 다이어트 자취요리\n",
      "Topic #19: 플레이브 plave 밤비 하민 예준 은호 노아 dash 2주년 hamin\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# 1. CSV 파일 로드\n",
    "input_file = \"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/preprocessed_data_comp.csv\"  # 전처리된 CSV 파일 경로\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 2. combined_text 열 생성: 만약 combined_text가 없으면, title, tags, img_text를 결합\n",
    "if \"combined_text\" not in df.columns:\n",
    "    # 각 열의 결측치는 빈 문자열로 처리하여 결합\n",
    "    df[\"combined_text\"] = (\n",
    "        df[\"title\"].fillna(\"\") + \" \" +\n",
    "        df[\"tags\"].fillna(\"\") + \" \" +\n",
    "        df[\"img_text\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "# 3. 결합된 텍스트를 문서 리스트로 생성\n",
    "docs = df[\"combined_text\"].fillna(\"\").tolist()\n",
    "\n",
    "# 4. TF-IDF 행렬 생성\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "# 5. NMF 모델 학습\n",
    "n_topics = 20  # 원하는 토픽 수\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf_model.fit_transform(tfidf)  # 문서-토픽 행렬\n",
    "H = nmf_model.components_           # 토픽-단어 행렬\n",
    "\n",
    "# 6. 각 토픽별 상위 단어 추출 함수\n",
    "def get_top_words(model, feature_names, n_top_words=10):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_indices = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topics.append(\" \".join(top_words))\n",
    "    return topics\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "topics = get_top_words(nmf_model, feature_names, n_top_words=10)\n",
    "\n",
    "# 7. 토픽 결과 출력 및 파일로 저장\n",
    "for i, topic in enumerate(topics):\n",
    "    print(\"Topic #{}: {}\".format(i, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YT_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
