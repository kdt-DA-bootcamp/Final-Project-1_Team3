{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.033*\"코디\" + 0.028*\"패션\" + 0.026*\"스타\" + 0.021*\"건강\" + 0.019*\"남자\" + 0.015*\"추천\" + 0.014*\"일리\" + 0.013*\"일링\" + 0.011*\"중년\" + 0.011*\"여성\"')\n",
      "(1, '0.033*\"게임\" + 0.020*\"영어\" + 0.011*\"공략\" + 0.008*\"리뷰\" + 0.008*\"오브\" + 0.007*\"공부\" + 0.007*\"냉장고\" + 0.007*\"vs\" + 0.007*\"모바일\" + 0.006*\"하이라이트\"')\n",
      "(2, '0.026*\"로그\" + 0.025*\"여행\" + 0.024*\"먹방\" + 0.024*\"브이\" + 0.019*\"맛집\" + 0.015*\"요리\" + 0.012*\"레시피\" + 0.009*\"일상\" + 0.009*\"추천\" + 0.008*\"asmr\"')\n",
      "(3, '0.039*\"동요\" + 0.027*\"아기\" + 0.022*\"놀이\" + 0.017*\"언박싱\" + 0.017*\"개월\" + 0.016*\"만들기\" + 0.015*\"어린이\" + 0.012*\"메이크업\" + 0.010*\"추천\" + 0.010*\"육아\"')\n",
      "(4, '0.066*\"하다\" + 0.017*\"있다\" + 0.015*\"체험\" + 0.012*\"되다\" + 0.011*\"보다\" + 0.010*\"좋다\" + 0.008*\"없다\" + 0.007*\"사람\" + 0.006*\"이다\" + 0.006*\"shorts\"')\n",
      "(5, '0.017*\"강의\" + 0.016*\"취업\" + 0.016*\"뉴스\" + 0.013*\"교육\" + 0.012*\"아이폰\" + 0.008*\"아파트\" + 0.008*\"유아\" + 0.007*\"부동산\" + 0.007*\"공부\" + 0.007*\"신축\"')\n",
      "(6, '0.027*\"추천\" + 0.025*\"스마트폰\" + 0.023*\"컴퓨터\" + 0.018*\"비교\" + 0.017*\"리뷰\" + 0.011*\"가전\" + 0.011*\"코인\" + 0.011*\"갤럭시\" + 0.010*\"삼성\" + 0.009*\"가격\"')\n",
      "(7, '0.031*\"영화\" + 0.027*\"드라마\" + 0.024*\"배우\" + 0.014*\"한국\" + 0.012*\"리뷰\" + 0.009*\"예능\" + 0.008*\"하다\" + 0.008*\"폭싹\" + 0.008*\"추천\" + 0.006*\"보기\"')\n",
      "(8, '0.056*\"직캠\" + 0.044*\"아이돌\" + 0.012*\"세라핌\" + 0.011*\"라이브\" + 0.010*\"치어리더\" + 0.010*\"골프\" + 0.009*\"콘서트\" + 0.009*\"트롯\" + 0.008*\"트로트\" + 0.007*\"하츠\"')\n",
      "(9, '0.049*\"린지\" + 0.042*\"채다\" + 0.032*\"댄스\" + 0.031*\"노래\" + 0.022*\"춤추다\" + 0.016*\"음악\" + 0.014*\"플레이\" + 0.013*\"추천\" + 0.013*\"kpop\" + 0.013*\"dance\"')\n",
      "LDA 토픽 모델링 결과가 'lda_topics.txt' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# 1. CSV 파일 불러오기 (전처리된 파일)\n",
    "df = pd.read_csv(\"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/preprocessed_data_3.csv\")\n",
    "\n",
    "# 2. title_tokens, tags_tokens, img_text_tokens 컬럼의 토큰들을 결합하는 함수\n",
    "def combine_tokens(row):\n",
    "    tokens = []\n",
    "    # 각 컬럼에 대해 문자열을 실제 리스트로 변환 후 합치기\n",
    "    for col in [\"title_tokens\", \"tags_tokens\", \"img_text_tokens\"]:\n",
    "        if pd.notnull(row[col]):\n",
    "            try:\n",
    "                tokens.extend(ast.literal_eval(row[col]))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return tokens\n",
    "\n",
    "# 결합된 토큰 리스트를 새로운 컬럼에 저장\n",
    "df[\"all_tokens\"] = df.apply(combine_tokens, axis=1)\n",
    "\n",
    "# 3. 토픽 모델링을 위한 데이터 준비\n",
    "# 각 문서(행)에 대해 토큰 리스트를 추출\n",
    "texts = df[\"all_tokens\"].tolist()\n",
    "\n",
    "# 단어 사전(dictionary) 생성\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "# 코퍼스: 각 문서를 bag-of-words (단어-빈도) 형식으로 변환\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# 4. LDA 토픽 모델 학습\n",
    "num_topics = 10  # 원하는 토픽 수 설정 (예: 10)\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=num_topics,\n",
    "                     random_state=42,\n",
    "                     passes=10)\n",
    "\n",
    "# 5. 토픽 결과 출력 및 저장\n",
    "topics = lda_model.print_topics(num_topics=num_topics)\n",
    "\n",
    "# 토픽을 화면에 출력\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "# LDA 모델 저장 (나중에 재사용 가능)\n",
    "lda_model.save(\"lda_model.model\")\n",
    "\n",
    "# 토픽 결과를 텍스트 파일로 저장\n",
    "with open(\"lda_topics.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for topic in topics:\n",
    "        f.write(str(topic) + \"\\n\")\n",
    "\n",
    "print(\"LDA 토픽 모델링 결과가 'lda_topics.txt' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.030*\"아기\" + 0.025*\"맛집\" + 0.022*\"코인\" + 0.019*\"여행\" + 0.018*\"주식\" + 0.017*\"어린이\" + 0.016*\"개월\" + 0.010*\"매매\" + 0.010*\"투자\" + 0.009*\"유아\"')\n",
      "(1, '0.059*\"동요\" + 0.059*\"영화\" + 0.032*\"드라마\" + 0.024*\"리뷰\" + 0.024*\"춤추다\" + 0.017*\"교육\" + 0.013*\"골프\" + 0.012*\"애니메이션\" + 0.012*\"추천\" + 0.010*\"넷플릭스\"')\n",
      "(2, '0.025*\"노래\" + 0.023*\"갤럭시\" + 0.015*\"음악\" + 0.014*\"플레이\" + 0.012*\"놀이\" + 0.009*\"리스트\" + 0.009*\"모음\" + 0.008*\"감성\" + 0.007*\"추천\" + 0.006*\"무선\"')\n",
      "(3, '0.041*\"직캠\" + 0.032*\"아이돌\" + 0.022*\"댄스\" + 0.013*\"kpop\" + 0.009*\"세라핌\" + 0.008*\"폭싹\" + 0.008*\"치어리더\" + 0.007*\"수다\" + 0.007*\"콘서트\" + 0.007*\"shorts\"')\n",
      "(4, '0.029*\"로그\" + 0.028*\"브이\" + 0.026*\"언박싱\" + 0.017*\"요리\" + 0.013*\"레시피\" + 0.013*\"일상\" + 0.012*\"건강\" + 0.012*\"일본\" + 0.011*\"만들기\" + 0.008*\"다이어트\"')\n",
      "(5, '0.022*\"체험\" + 0.021*\"먹방\" + 0.021*\"한국\" + 0.018*\"뉴스\" + 0.010*\"여행\" + 0.010*\"해외\" + 0.009*\"미국\" + 0.009*\"기술\" + 0.008*\"부동산\" + 0.007*\"중국\"')\n",
      "(6, '0.055*\"하다\" + 0.019*\"배우\" + 0.014*\"있다\" + 0.013*\"되다\" + 0.011*\"취업\" + 0.011*\"보다\" + 0.008*\"이유\" + 0.008*\"좋다\" + 0.008*\"드라마\" + 0.008*\"아이폰\"')\n",
      "(7, '0.046*\"스마트폰\" + 0.027*\"비교\" + 0.021*\"강의\" + 0.018*\"삼성\" + 0.011*\"프로\" + 0.011*\"AI\" + 0.009*\"전자\" + 0.009*\"리뷰\" + 0.008*\"vs\" + 0.008*\"사용\"')\n",
      "(8, '0.047*\"린지\" + 0.040*\"채다\" + 0.030*\"게임\" + 0.026*\"가전\" + 0.019*\"알리\" + 0.012*\"아파트\" + 0.011*\"빌라\" + 0.010*\"공략\" + 0.010*\"신축\" + 0.009*\"곰돌\"')\n",
      "(9, '0.050*\"추천\" + 0.027*\"컴퓨터\" + 0.018*\"리뷰\" + 0.013*\"코디\" + 0.011*\"패션\" + 0.011*\"TOP\" + 0.010*\"가성\" + 0.010*\"제품\" + 0.010*\"쿠팡\" + 0.010*\"스타\"')\n",
      "LDA 토픽 모델링 결과가 'lda_topics_with_comp.txt' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# 1. CSV 파일 불러오기 (전처리된 파일)\n",
    "df = pd.read_csv(\"C:/Users/hp/Desktop/Bootcamp/PROJECT_OTT_AARRR/preprocessed_data_comp.csv\")\n",
    "\n",
    "# 2. title_tokens, tags_tokens, img_text_tokens 컬럼의 토큰들을 결합하는 함수\n",
    "def combine_tokens(row):\n",
    "    tokens = []\n",
    "    # 각 컬럼에 대해 문자열을 실제 리스트로 변환 후 합치기\n",
    "    for col in [\"title_tokens\", \"tags_tokens\", \"img_text_tokens\"]:\n",
    "        if pd.notnull(row[col]):\n",
    "            try:\n",
    "                tokens.extend(ast.literal_eval(row[col]))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return tokens\n",
    "\n",
    "# 결합된 토큰 리스트를 새로운 컬럼에 저장\n",
    "df[\"all_tokens\"] = df.apply(combine_tokens, axis=1)\n",
    "\n",
    "# 3. 토픽 모델링을 위한 데이터 준비\n",
    "# 각 문서(행)에 대해 토큰 리스트를 추출\n",
    "texts = df[\"all_tokens\"].tolist()\n",
    "\n",
    "# 단어 사전(dictionary) 생성\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "# 코퍼스: 각 문서를 bag-of-words (단어-빈도) 형식으로 변환\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# 4. LDA 토픽 모델 학습\n",
    "num_topics = 10  # 원하는 토픽 수 설정 (예: 10)\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=num_topics,\n",
    "                     random_state=42,\n",
    "                     passes=10)\n",
    "\n",
    "# 5. 토픽 결과 출력 및 저장\n",
    "topics = lda_model.print_topics(num_topics=num_topics)\n",
    "\n",
    "# 토픽을 화면에 출력\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "# LDA 모델 저장 (나중에 재사용 가능)\n",
    "lda_model.save(\"lda_model_with_comp.model\")\n",
    "\n",
    "# 토픽 결과를 텍스트 파일로 저장\n",
    "with open(\"lda_topics_with_comp.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for topic in topics:\n",
    "        f.write(str(topic) + \"\\n\")\n",
    "\n",
    "print(\"LDA 토픽 모델링 결과가 'lda_topics_with_comp.txt' 파일에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YT_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
