{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT모델 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Google Drive 마운트 (최초 실행 시 인증 필요)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.optim as optim  # torch의 AdamW 사용\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# 3. 커스텀 데이터셋 클래스 정의\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, csv_path, tokenizer, max_length=128):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        # title, tags, img_text를 하나의 문자열로 결합\n",
    "        text = f\"{row['title']} {row['tags']} {row['img_text']}\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # extra 차원 제거\n",
    "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "        # 'category' 컬럼 값이 1~10 범위라고 가정 (0부터 시작하도록 조정)\n",
    "        label = torch.tensor(row['category'] - 1)\n",
    "        return inputs, label\n",
    "\n",
    "# 4. BERT 기반 분류 모델 정의\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 10)  # 10개 카테고리\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output  # [CLS] 토큰 임베딩\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# 5. 경로 설정 및 데이터셋 준비 (경로는 자신의 Google Drive 내 파일 위치에 맞게 수정)\n",
    "csv_path = \"/content/drive/MyDrive/path_to_your_csv/filtered_video_data.csv\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "dataset = VideoDataset(csv_path, tokenizer, max_length=128)\n",
    "\n",
    "# DataLoader 최적화: 배치 사이즈 32, num_workers=4, pin_memory 활성화\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 6. 모델, 옵티마이저, 손실 함수 및 mixed precision을 위한 GradScaler 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertClassifier().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()  # mixed precision을 위한 스케일러\n",
    "\n",
    "# 7. 학습 루프 (Mixed Precision Training 적용)\n",
    "epochs = 3\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch\n",
    "        input_ids = inputs[\"input_ids\"].to(device, non_blocking=True)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 자동 혼합 정밀도 적용\n",
    "        with autocast():\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 8. 학습 완료 후 모델 저장 (Google Drive 경로에 저장)\n",
    "torch.save(model.state_dict(), \"/content/drive/MyDrive/path_to_your_csv/bert_classifier.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YT_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
